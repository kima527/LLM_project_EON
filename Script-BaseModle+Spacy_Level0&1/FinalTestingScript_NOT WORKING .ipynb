{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH_bLLB6W2qE",
        "outputId": "ba7b40e0-8d45-4b2c-d9d9-14d47b59615a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Testing Version**\n",
        "This script evaluates the quality of text anonymization using a span-based comparison between the original, ground truth, and anonymized (PIIRanha) versions of a text.\n",
        "\n",
        "**It performs the following steps:**\n",
        "\n",
        "\n",
        "1.   **Tokenization:** Splits the text into tokens (words, numbers, punctuation).\n",
        "2.   **Label Alignment:** Aligns ground truth and anonymized labels to the original text.\n",
        "3.   **Span Extraction:** Extracts labeled spans (e.g., names, dates) from both ground truth and anonymized versions.\n",
        "4. **Span Matching:** Compares which ground truth spans were correctly anonymized.\n",
        "5. **Metric Calculation:** Computes precision, recall, and F1 score for each label type\n",
        "6. **Evaluation Across Multiple Examples:** For multiple files: evaluates & calculates aggregate metrics.\n",
        "\n",
        "\n",
        "\n",
        "**The output includes:**\n",
        "1. Detailed span-level matching results\n",
        "\n",
        "2. Metrics per label type\n",
        "\n",
        "3. Overall anonymization coverage\n",
        "\n",
        "4. Summary of results across all examples"
      ],
      "metadata": {
        "id": "xNO_caZ5Zy6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global SetUp"
      ],
      "metadata": {
        "id": "m2IdbxzoXBog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import**"
      ],
      "metadata": {
        "id": "I3PKiaaHXPUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "from difflib import SequenceMatcher"
      ],
      "metadata": {
        "id": "btNR0cRiXTc3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SpanEvaluator**"
      ],
      "metadata": {
        "id": "VSeQ1poKXU5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PIIRanhaSpanEvaluator:\n",
        "    \"\"\"\n",
        "    Pr√§ziser Evaluator f√ºr PIIRanha - pr√ºft tats√§chliche Textspan-Anonymisierung\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.label_types = [\n",
        "            'GIVENNAME', 'SURNAME', 'ACCOUNTNUM', 'Year',\n",
        "            'DATE', 'DAY', 'MONTH'\n",
        "        ]\n",
        "\n",
        "    def tokenize_text(self, text):\n",
        "        \"\"\"\n",
        "        Intelligente Tokenisierung die W√∂rter, Zahlen und Satzzeichen trennt\n",
        "        \"\"\"\n",
        "        # Regex f√ºr Tokenisierung: W√∂rter, Zahlen, Satzzeichen\n",
        "        tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
        "        return tokens\n",
        "\n",
        "    def align_texts_with_labels(self, original_text, labeled_text):\n",
        "        \"\"\"\n",
        "        Erstellt ein Alignment zwischen Original und Label-Text\n",
        "        Gibt zur√ºck: Liste von (original_token, label_info)\n",
        "        \"\"\"\n",
        "        original_tokens = self.tokenize_text(original_text)\n",
        "\n",
        "        # Spezielle Tokenisierung f√ºr Label-Text\n",
        "        labeled_tokens = []\n",
        "        current_pos = 0\n",
        "\n",
        "        # Finde alle Labels im Text\n",
        "        label_pattern = r'\\[([^\\]]+)\\]'\n",
        "\n",
        "        for match in re.finditer(label_pattern, labeled_text):\n",
        "            # Text vor dem Label\n",
        "            before_label = labeled_text[current_pos:match.start()]\n",
        "            if before_label.strip():\n",
        "                labeled_tokens.extend(self.tokenize_text(before_label))\n",
        "\n",
        "            # Das Label selbst\n",
        "            labeled_tokens.append({\n",
        "                'type': 'LABEL',\n",
        "                'label': match.group(1),\n",
        "                'full_match': match.group(0)\n",
        "            })\n",
        "\n",
        "            current_pos = match.end()\n",
        "\n",
        "        # Rest des Textes nach dem letzten Label\n",
        "        remaining_text = labeled_text[current_pos:]\n",
        "        if remaining_text.strip():\n",
        "            labeled_tokens.extend(self.tokenize_text(remaining_text))\n",
        "\n",
        "        # Alignment zwischen Original und Label-Tokens\n",
        "        alignment = self._align_token_sequences(original_tokens, labeled_tokens)\n",
        "\n",
        "        return alignment\n",
        "\n",
        "    def _align_token_sequences(self, original_tokens, labeled_tokens):\n",
        "        \"\"\"\n",
        "        Aligniert Original-Tokens mit Label-Tokens\n",
        "        \"\"\"\n",
        "        alignment = []\n",
        "        orig_idx = 0\n",
        "        label_idx = 0\n",
        "\n",
        "        while orig_idx < len(original_tokens) and label_idx < len(labeled_tokens):\n",
        "            labeled_token = labeled_tokens[label_idx]\n",
        "\n",
        "            if isinstance(labeled_token, dict) and labeled_token['type'] == 'LABEL':\n",
        "                label_span_start = orig_idx\n",
        "\n",
        "                # Z√§hle wie viele Labels direkt nacheinander folgen\n",
        "                lookahead = label_idx + 1\n",
        "                next_labels = 0\n",
        "                while lookahead < len(labeled_tokens):\n",
        "                    if isinstance(labeled_tokens[lookahead], dict):\n",
        "                        next_labels += 1\n",
        "                        lookahead += 1\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "                num_labels_in_a_row = next_labels + 1  # inklusive dieses Labels\n",
        "\n",
        "                # Verteilt die n√§chsten N Original-Tokens auf die Labels\n",
        "                tokens_per_label = 1  # Annahme: 1 Token pro Label\n",
        "\n",
        "                # Zuweisung: aktueller Label bekommt 1 Token\n",
        "                if orig_idx < len(original_tokens):\n",
        "                    alignment.append({\n",
        "                        'original_token': original_tokens[orig_idx],\n",
        "                        'original_index': orig_idx,\n",
        "                        'label_type': labeled_token['label'],\n",
        "                        'is_labeled': True\n",
        "                    })\n",
        "                    orig_idx += 1\n",
        "\n",
        "                label_idx += 1\n",
        "\n",
        "\n",
        "            else:\n",
        "                # Normaler Token - sollte √ºbereinstimmen\n",
        "                if self._tokens_match(original_tokens[orig_idx], labeled_token):\n",
        "                    alignment.append({\n",
        "                        'original_token': original_tokens[orig_idx],\n",
        "                        'original_index': orig_idx,\n",
        "                        'label_type': None,\n",
        "                        'is_labeled': False\n",
        "                    })\n",
        "                    orig_idx += 1\n",
        "                    label_idx += 1\n",
        "                else:\n",
        "                    # Tokens stimmen nicht √ºberein - versuche zu synchronisieren\n",
        "                    orig_idx += 1\n",
        "\n",
        "        return alignment\n",
        "\n",
        "    def _tokens_match(self, token1, token2):\n",
        "        \"\"\"\n",
        "        Pr√ºft ob zwei Tokens √ºbereinstimmen (case-insensitive)\n",
        "        \"\"\"\n",
        "        if isinstance(token1, dict) or isinstance(token2, dict):\n",
        "            return False\n",
        "        return str(token1).lower().strip() == str(token2).lower().strip()\n",
        "\n",
        "    def extract_label_spans(self, alignment):\n",
        "        \"\"\"\n",
        "        Extrahiert Label-Spans aus einem Alignment\n",
        "        \"\"\"\n",
        "        spans = []\n",
        "        current_span = None\n",
        "\n",
        "        for item in alignment:\n",
        "            if item['is_labeled']:\n",
        "                if current_span is None or current_span['label_type'] != item['label_type']:\n",
        "                    # Neuer Span beginnt\n",
        "                    if current_span is not None:\n",
        "                        spans.append(current_span)\n",
        "\n",
        "                    current_span = {\n",
        "                        'label_type': item['label_type'],\n",
        "                        'original_tokens': [item['original_token']],\n",
        "                        'original_indices': [item['original_index']],\n",
        "                        'original_text': item['original_token']\n",
        "                    }\n",
        "                else:\n",
        "                    # Span fortsetzung\n",
        "                    current_span['original_tokens'].append(item['original_token'])\n",
        "                    current_span['original_indices'].append(item['original_index'])\n",
        "                    current_span['original_text'] += ' ' + item['original_token']\n",
        "            else:\n",
        "                # Nicht-Label Token - aktueller Span endet\n",
        "                if current_span is not None:\n",
        "                    spans.append(current_span)\n",
        "                    current_span = None\n",
        "\n",
        "        # Letzten Span hinzuf√ºgen falls vorhanden\n",
        "        if current_span is not None:\n",
        "            spans.append(current_span)\n",
        "\n",
        "        return spans\n",
        "\n",
        "    def evaluate_span_coverage(self, original_text, piiranha_text, ground_truth_text):\n",
        "        \"\"\"\n",
        "        Hauptevaluierungsfunktion - pr√ºft Span-basierte Abdeckung\n",
        "        \"\"\"\n",
        "        print(\"üîç Starte Span-basierte Evaluierung...\")\n",
        "\n",
        "        # 1. Alignments erstellen\n",
        "        print(\"üìù Erstelle Alignments...\")\n",
        "        ground_truth_alignment = self.align_texts_with_labels(original_text, ground_truth_text)\n",
        "        piiranha_alignment = self.align_texts_with_labels(original_text, piiranha_text)\n",
        "\n",
        "        # 2. Label-Spans extrahieren\n",
        "        print(\"üéØ Extrahiere Label-Spans...\")\n",
        "        ground_truth_spans = self.extract_label_spans(ground_truth_alignment)\n",
        "        piiranha_spans = self.extract_label_spans(piiranha_alignment)\n",
        "\n",
        "        print(f\"üìä Ground Truth Spans: {len(ground_truth_spans)}\")\n",
        "        print(f\"üìä PIIRanha Spans: {len(piiranha_spans)}\")\n",
        "\n",
        "        # 3. Span-Vergleich\n",
        "        print(\"‚öñÔ∏è Vergleiche Spans...\")\n",
        "        results = self._compare_spans(ground_truth_spans, piiranha_spans)\n",
        "\n",
        "        # 4. Debug-Informationen\n",
        "        self._print_debug_info(ground_truth_spans, piiranha_spans, results)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _compare_spans(self, ground_truth_spans, piiranha_spans):\n",
        "        \"\"\"\n",
        "        Vergleicht Ground Truth Spans mit PIIRanha Spans\n",
        "        \"\"\"\n",
        "        # Erstelle Index f√ºr PIIRanha Spans nach Token-Indizes\n",
        "        piiranha_index = {}\n",
        "        for span in piiranha_spans:\n",
        "            for idx in span['original_indices']:\n",
        "                piiranha_index[idx] = span\n",
        "\n",
        "        # Evaluiere jeden Ground Truth Span\n",
        "        span_results = []\n",
        "        label_metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})\n",
        "\n",
        "        for gt_span in ground_truth_spans:\n",
        "            # Pr√ºfe ob PIIRanha diesen Span abgedeckt hat\n",
        "            covered_indices = []\n",
        "            piiranha_labels = set()\n",
        "\n",
        "            for idx in gt_span['original_indices']:\n",
        "                if idx in piiranha_index:\n",
        "                    covered_indices.append(idx)\n",
        "                    piiranha_labels.add(piiranha_index[idx]['label_type'])\n",
        "\n",
        "            # Bestimme Abdeckungsgrad\n",
        "            coverage_ratio = len(covered_indices) / len(gt_span['original_indices'])\n",
        "\n",
        "            # Bestimme ob es ein Match ist (>= 50% √úberlappung)\n",
        "            is_exact_match = coverage_ratio >= 0.5\n",
        "            label_match = gt_span['label_type'] in piiranha_labels\n",
        "\n",
        "            span_result = {\n",
        "                'ground_truth_span': gt_span,\n",
        "                'coverage_ratio': coverage_ratio,\n",
        "                'is_covered': is_exact_match,\n",
        "                'label_match': label_match,\n",
        "                'piiranha_labels': list(piiranha_labels),\n",
        "                'covered_indices': covered_indices\n",
        "            }\n",
        "\n",
        "            span_results.append(span_result)\n",
        "\n",
        "            # Update Metriken\n",
        "            if is_exact_match and label_match:\n",
        "                label_metrics[gt_span['label_type']]['tp'] += 1\n",
        "            else:\n",
        "                label_metrics[gt_span['label_type']]['fn'] += 1\n",
        "\n",
        "        # Finde False Positives (PIIRanha Spans die nicht in Ground Truth sind)\n",
        "        gt_indices = set()\n",
        "        for span in ground_truth_spans:\n",
        "            gt_indices.update(span['original_indices'])\n",
        "\n",
        "        for span in piiranha_spans:\n",
        "            span_indices = set(span['original_indices'])\n",
        "            if not span_indices.intersection(gt_indices):\n",
        "                # Dieser PIIRanha Span hat keine √úberlappung mit Ground Truth\n",
        "                label_metrics[span['label_type']]['fp'] += 1\n",
        "\n",
        "        # Berechne finale Metriken\n",
        "        final_metrics = {}\n",
        "        for label_type, counts in label_metrics.items():\n",
        "            tp, fp, fn = counts['tp'], counts['fp'], counts['fn']\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            final_metrics[label_type] = {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1,\n",
        "                'true_positives': tp,\n",
        "                'false_positives': fp,\n",
        "                'false_negatives': fn\n",
        "            }\n",
        "\n",
        "        # Gesamtabdeckung\n",
        "        total_gt_spans = len(ground_truth_spans)\n",
        "        covered_spans = sum(1 for r in span_results if r['is_covered'] and r['label_match'])\n",
        "        overall_coverage = covered_spans / total_gt_spans if total_gt_spans > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'span_results': span_results,\n",
        "            'label_metrics': final_metrics,\n",
        "            'overall_coverage': overall_coverage,\n",
        "            'total_ground_truth_spans': total_gt_spans,\n",
        "            'total_covered_spans': covered_spans\n",
        "        }\n",
        "\n",
        "    def _print_debug_info(self, ground_truth_spans, piiranha_spans, results):\n",
        "        \"\"\"\n",
        "        Gibt detaillierte Debug-Informationen aus\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üîç DETAILLIERTE SPAN-ANALYSE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(f\"\\nüìã GROUND TRUTH SPANS ({len(ground_truth_spans)}):\")\n",
        "        for i, span in enumerate(ground_truth_spans, 1):\n",
        "            print(f\"  {i}. [{span['label_type']}] ‚Üí '{span['original_text']}' (Indices: {span['original_indices']})\")\n",
        "\n",
        "        print(f\"\\nü§ñ PIIRANHA SPANS ({len(piiranha_spans)}):\")\n",
        "        for i, span in enumerate(piiranha_spans, 1):\n",
        "            print(f\"  {i}. [{span['label_type']}] ‚Üí '{span['original_text']}' (Indices: {span['original_indices']})\")\n",
        "\n",
        "        print(f\"\\n‚úÖ SPAN-MATCHING ERGEBNISSE:\")\n",
        "        for i, result in enumerate(results['span_results'], 1):\n",
        "            gt_span = result['ground_truth_span']\n",
        "            status = \"‚úÖ ERKANNT\" if result['is_covered'] and result['label_match'] else \"‚ùå VERFEHLT\"\n",
        "            print(f\"  {i}. [{gt_span['label_type']}] '{gt_span['original_text']}' ‚Üí {status}\")\n",
        "            print(f\"     Abdeckung: {result['coverage_ratio']:.1%}, PIIRanha Labels: {result['piiranha_labels']}\")\n",
        "\n",
        "    def print_results(self, results):\n",
        "        \"\"\"\n",
        "        Gibt die finalen Ergebnisse formatiert aus\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"üìä PIIRANHA SPAN-BASIERTE EVALUATION ERGEBNISSE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        print(f\"\\nüéØ GESAMTABDECKUNG: {results['overall_coverage']:.1%}\")\n",
        "\n",
        "        # Nur anzeigen wenn die Keys existieren (einzelne Ergebnisse)\n",
        "        if 'total_covered_spans' in results and 'total_ground_truth_spans' in results:\n",
        "            print(f\"   Erkannte Spans: {results['total_covered_spans']}/{results['total_ground_truth_spans']}\")\n",
        "\n",
        "        print(f\"\\nüìà METRIKEN PRO LABEL-TYP:\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        df_data = []\n",
        "        for label_type, metrics in results['label_metrics'].items():\n",
        "            df_data.append({\n",
        "                'Label Type': label_type,\n",
        "                'Precision': f\"{metrics['precision']:.3f}\",\n",
        "                'Recall': f\"{metrics['recall']:.3f}\",\n",
        "                'F1-Score': f\"{metrics['f1_score']:.3f}\",\n",
        "                'TP': metrics['true_positives'],\n",
        "                'FP': metrics['false_positives'],\n",
        "                'FN': metrics['false_negatives']\n",
        "            })\n",
        "\n",
        "        if df_data:\n",
        "            df = pd.DataFrame(df_data)\n",
        "            print(df.to_string(index=False))\n",
        "        else:\n",
        "            print(\"Keine Metriken verf√ºgbar.\")\n",
        "\n",
        "    def evaluate_multiple_examples(self, examples):\n",
        "        \"\"\"\n",
        "        Evaluiert mehrere Beispiele\n",
        "        \"\"\"\n",
        "        all_results = []\n",
        "        aggregated_metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})\n",
        "\n",
        "        for i, example in enumerate(examples):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"üìù EVALUIERE BEISPIEL {i+1}/{len(examples)}\")\n",
        "            print('='*60)\n",
        "\n",
        "            result = self.evaluate_span_coverage(\n",
        "                example['original'],\n",
        "                example['piiranha'],\n",
        "                example['ground_truth']\n",
        "            )\n",
        "\n",
        "            all_results.append(result)\n",
        "            self.print_results(result)\n",
        "\n",
        "            # Aggregiere Metriken\n",
        "            for label_type, metrics in result['label_metrics'].items():\n",
        "                aggregated_metrics[label_type]['tp'] += metrics['true_positives']\n",
        "                aggregated_metrics[label_type]['fp'] += metrics['false_positives']\n",
        "                aggregated_metrics[label_type]['fn'] += metrics['false_negatives']\n",
        "\n",
        "        # Berechne aggregierte Metriken\n",
        "        final_aggregated = {}\n",
        "        for label_type, counts in aggregated_metrics.items():\n",
        "            tp, fp, fn = counts['tp'], counts['fp'], counts['fn']\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            final_aggregated[label_type] = {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1,\n",
        "                'true_positives': tp,\n",
        "                'false_positives': fp,\n",
        "                'false_negatives': fn\n",
        "            }\n",
        "\n",
        "        # Durchschnittliche Coverage\n",
        "        avg_coverage = np.mean([r['overall_coverage'] for r in all_results])\n",
        "\n",
        "        # Finale Ausgabe\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"üèÜ AGGREGIERTE ERGEBNISSE √úBER ALLE BEISPIELE\")\n",
        "        print('='*80)\n",
        "        print(f\"\\nüéØ DURCHSCHNITTLICHE ABDECKUNG: {avg_coverage:.1%}\")\n",
        "\n",
        "        aggregated_results = {\n",
        "            'label_metrics': final_aggregated,\n",
        "            'overall_coverage': avg_coverage\n",
        "        }\n",
        "\n",
        "        self.print_results(aggregated_results)\n",
        "\n",
        "        return {\n",
        "            'individual_results': all_results,\n",
        "            'aggregated_results': aggregated_results\n",
        "        }"
      ],
      "metadata": {
        "id": "zR3P9lGEYDhd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Old Import & Upload Function** - do not use it"
      ],
      "metadata": {
        "id": "PsLFqOUwYGu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from google.colab import files  # for Colab\n",
        "uploaded = files.upload()\n",
        "\n",
        "def load_multiple_examples(count=10):\n",
        "    examples = []\n",
        "    for i in range(1, count + 1):\n",
        "        with open(f\"original_{i}.txt\", encoding='utf-8') as f1, \\\n",
        "             open(f\"groundtruth_{i}.txt\", encoding='utf-8') as f2, \\\n",
        "             open(f\"piiranha_{i}.txt\", encoding='utf-8') as f3:\n",
        "\n",
        "            examples.append({\n",
        "                'original': f1.read(),\n",
        "                'ground_truth': f2.read(),\n",
        "                'piiranha': f3.read()\n",
        "            })\n",
        "    return examples\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "collapsed": true,
        "id": "lOFNnCxwYOSR",
        "outputId": "a47e1382-1b05-40ca-cce2-45015fdc7c4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd373cd9-096f-4727-8924-b6d49bd59f2f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd373cd9-096f-4727-8924-b6d49bd59f2f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving original_1.txt to original_1 (2).txt\n",
            "Saving groundtruth_1.txt to groundtruth_1 (2).txt\n",
            "Saving piiranha_1.txt to piiranha_1 (2).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New Upload Function**"
      ],
      "metadata": {
        "id": "6G4GDpjnbNlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# Upload f√ºr original-Dateien\n",
        "print(\"üìÇ Bitte ORIGINAL-Dateien hochladen (z.‚ÄØB. original_1.txt)\")\n",
        "uploaded_original = files.upload()\n",
        "\n",
        "# Upload f√ºr ground truth-Dateien\n",
        "print(\"üìÇ Bitte GROUNDTRUTH-Dateien hochladen (z.‚ÄØB. groundtruth_1.txt)\")\n",
        "uploaded_groundtruth = files.upload()\n",
        "\n",
        "# Upload f√ºr piiranha-Ausgaben\n",
        "print(\"üìÇ Bitte PIIRANHA-Dateien hochladen (z.‚ÄØB. piiranha_1.txt)\")\n",
        "uploaded_piiranha = files.upload()\n",
        "\n",
        "def build_examples_from_uploads(uploaded_original, uploaded_groundtruth, uploaded_piiranha):\n",
        "    examples = []\n",
        "\n",
        "    for orig_filename, orig_content in uploaded_original.items():\n",
        "        # Basisname extrahieren: z.‚ÄØB. \"original_1.txt\" ‚Üí \"1\"\n",
        "        match = re.search(r'original_(\\d+)\\.txt', orig_filename)\n",
        "        if not match:\n",
        "            continue\n",
        "        file_id = match.group(1)\n",
        "\n",
        "        ground_filename = f\"groundtruth_{file_id}.txt\"\n",
        "        piiranha_filename = f\"piiranha_{file_id}.txt\"\n",
        "\n",
        "        # Dateien m√ºssen in allen Sets vorhanden sein\n",
        "        if ground_filename not in uploaded_groundtruth or piiranha_filename not in uploaded_piiranha:\n",
        "            print(f\"‚ö†Ô∏è Datei fehlt f√ºr ID {file_id}\")\n",
        "            continue\n",
        "\n",
        "        examples.append({\n",
        "            'original': orig_content.decode('utf-8'),\n",
        "            'ground_truth': uploaded_groundtruth[ground_filename].decode('utf-8'),\n",
        "            'piiranha': uploaded_piiranha[piiranha_filename].decode('utf-8')\n",
        "        })\n",
        "\n",
        "    print(f\"‚úÖ {len(examples)} Beispiele erfolgreich geladen.\")\n",
        "    return examples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "hFKodEoEbPvQ",
        "outputId": "018079ae-11cb-4711-cac5-52c11bccc840"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Bitte ORIGINAL-Dateien hochladen (z.‚ÄØB. original_1.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f42db467-8eb9-4e97-8e03-639963ff727d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f42db467-8eb9-4e97-8e03-639963ff727d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving original_1.txt to original_1.txt\n",
            "üìÇ Bitte GROUNDTRUTH-Dateien hochladen (z.‚ÄØB. groundtruth_1.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-593e4185-26f8-482a-b9ec-60beb9dddcc8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-593e4185-26f8-482a-b9ec-60beb9dddcc8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving groundtruth_1.txt to groundtruth_1.txt\n",
            "üìÇ Bitte PIIRANHA-Dateien hochladen (z.‚ÄØB. piiranha_1.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c630f17e-07b3-4aa8-abf6-43fe4617f263\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c630f17e-07b3-4aa8-abf6-43fe4617f263\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving piiranha_1.txt to piiranha_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1h-dtl-cYImv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MainFunction**"
      ],
      "metadata": {
        "id": "_05EZgSpYSyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"üöÄ STARTE SPAN-BASIERTE PIIRANHA EVALUATION\")\n",
        "\n",
        "    evaluator = PIIRanhaSpanEvaluator()\n",
        "\n",
        "    # ‚õ≥ Richtig: Baue Beispiele direkt aus den Uploads!\n",
        "    examples = build_examples_from_uploads(uploaded_original, uploaded_groundtruth, uploaded_piiranha)\n",
        "\n",
        "    multiple_results = evaluator.evaluate_multiple_examples(examples)\n",
        "\n",
        "# üì¢ Danach einfach ausf√ºhren:\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1LuPDNpdmp4",
        "outputId": "2ef167a1-a7eb-4c20-9079-fcebb170cbc5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTE SPAN-BASIERTE PIIRANHA EVALUATION\n",
            "‚úÖ 1 Beispiele erfolgreich geladen.\n",
            "\n",
            "============================================================\n",
            "üìù EVALUIERE BEISPIEL 1/1\n",
            "============================================================\n",
            "üîç Starte Span-basierte Evaluierung...\n",
            "üìù Erstelle Alignments...\n",
            "üéØ Extrahiere Label-Spans...\n",
            "üìä Ground Truth Spans: 11\n",
            "üìä PIIRanha Spans: 5\n",
            "‚öñÔ∏è Vergleiche Spans...\n",
            "\n",
            "================================================================================\n",
            "üîç DETAILLIERTE SPAN-ANALYSE\n",
            "================================================================================\n",
            "\n",
            "üìã GROUND TRUTH SPANS (11):\n",
            "  1. [GIVENNAME] ‚Üí 'Catharina' (Indices: [10])\n",
            "  2. [SURNAME] ‚Üí 'Thies' (Indices: [11])\n",
            "  3. [ACCOUNTNUM] ‚Üí '402157398' (Indices: [14])\n",
            "  4. [Year] ‚Üí '2022' (Indices: [19])\n",
            "  5. [Year] ‚Üí '2023' (Indices: [21])\n",
            "  6. [DATE] ‚Üí '15' (Indices: [29])\n",
            "  7. [DAY] ‚Üí '16' (Indices: [44])\n",
            "  8. [MONTH] ‚Üí '05' (Indices: [46])\n",
            "  9. [DATE] ‚Üí '31' (Indices: [49])\n",
            "  10. [GIVENNAME] ‚Üí 'Catharina' (Indices: [79])\n",
            "  11. [SURNAME] ‚Üí 'Thies' (Indices: [80])\n",
            "\n",
            "ü§ñ PIIRANHA SPANS (5):\n",
            "  1. [GIVENNAME] ‚Üí 'Catharina' (Indices: [10])\n",
            "  2. [SURNAME] ‚Üí 'Thies' (Indices: [11])\n",
            "  3. [ACCOUNTNUM] ‚Üí '402157398' (Indices: [14])\n",
            "  4. [GIVENNAME] ‚Üí 'Catharina' (Indices: [79])\n",
            "  5. [SURNAME] ‚Üí 'Thies' (Indices: [80])\n",
            "\n",
            "‚úÖ SPAN-MATCHING ERGEBNISSE:\n",
            "  1. [GIVENNAME] 'Catharina' ‚Üí ‚úÖ ERKANNT\n",
            "     Abdeckung: 100.0%, PIIRanha Labels: ['GIVENNAME']\n",
            "  2. [SURNAME] 'Thies' ‚Üí ‚úÖ ERKANNT\n",
            "     Abdeckung: 100.0%, PIIRanha Labels: ['SURNAME']\n",
            "  3. [ACCOUNTNUM] '402157398' ‚Üí ‚úÖ ERKANNT\n",
            "     Abdeckung: 100.0%, PIIRanha Labels: ['ACCOUNTNUM']\n",
            "  4. [Year] '2022' ‚Üí ‚ùå VERFEHLT\n",
            "     Abdeckung: 0.0%, PIIRanha Labels: []\n",
            "  5. [Year] '2023' ‚Üí ‚ùå VERFEHLT\n",
            "     Abdeckung: 0.0%, PIIRanha Labels: []\n",
            "  6. [DATE] '15' ‚Üí ‚ùå VERFEHLT\n",
            "     Abdeckung: 0.0%, PIIRanha Labels: []\n",
            "  7. [DAY] '16' ‚Üí ‚ùå VERFEHLT\n",
            "     Abdeckung: 0.0%, PIIRanha Labels: []\n",
            "  8. [MONTH] '05' ‚Üí ‚ùå VERFEHLT\n",
            "     Abdeckung: 0.0%, PIIRanha Labels: []\n",
            "  9. [DATE] '31' ‚Üí ‚ùå VERFEHLT\n",
            "     Abdeckung: 0.0%, PIIRanha Labels: []\n",
            "  10. [GIVENNAME] 'Catharina' ‚Üí ‚úÖ ERKANNT\n",
            "     Abdeckung: 100.0%, PIIRanha Labels: ['GIVENNAME']\n",
            "  11. [SURNAME] 'Thies' ‚Üí ‚úÖ ERKANNT\n",
            "     Abdeckung: 100.0%, PIIRanha Labels: ['SURNAME']\n",
            "\n",
            "================================================================================\n",
            "üìä PIIRANHA SPAN-BASIERTE EVALUATION ERGEBNISSE\n",
            "================================================================================\n",
            "\n",
            "üéØ GESAMTABDECKUNG: 45.5%\n",
            "   Erkannte Spans: 5/11\n",
            "\n",
            "üìà METRIKEN PRO LABEL-TYP:\n",
            "--------------------------------------------------------------------------------\n",
            "Label Type Precision Recall F1-Score  TP  FP  FN\n",
            " GIVENNAME     1.000  1.000    1.000   2   0   0\n",
            "   SURNAME     1.000  1.000    1.000   2   0   0\n",
            "ACCOUNTNUM     1.000  1.000    1.000   1   0   0\n",
            "      Year     0.000  0.000    0.000   0   0   2\n",
            "      DATE     0.000  0.000    0.000   0   0   2\n",
            "       DAY     0.000  0.000    0.000   0   0   1\n",
            "     MONTH     0.000  0.000    0.000   0   0   1\n",
            "\n",
            "================================================================================\n",
            "üèÜ AGGREGIERTE ERGEBNISSE √úBER ALLE BEISPIELE\n",
            "================================================================================\n",
            "\n",
            "üéØ DURCHSCHNITTLICHE ABDECKUNG: 45.5%\n",
            "\n",
            "================================================================================\n",
            "üìä PIIRANHA SPAN-BASIERTE EVALUATION ERGEBNISSE\n",
            "================================================================================\n",
            "\n",
            "üéØ GESAMTABDECKUNG: 45.5%\n",
            "\n",
            "üìà METRIKEN PRO LABEL-TYP:\n",
            "--------------------------------------------------------------------------------\n",
            "Label Type Precision Recall F1-Score  TP  FP  FN\n",
            " GIVENNAME     1.000  1.000    1.000   2   0   0\n",
            "   SURNAME     1.000  1.000    1.000   2   0   0\n",
            "ACCOUNTNUM     1.000  1.000    1.000   1   0   0\n",
            "      Year     0.000  0.000    0.000   0   0   2\n",
            "      DATE     0.000  0.000    0.000   0   0   2\n",
            "       DAY     0.000  0.000    0.000   0   0   1\n",
            "     MONTH     0.000  0.000    0.000   0   0   1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Old Main Function - do not use it**"
      ],
      "metadata": {
        "id": "RmIarRZLeS8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Hauptfunktion f√ºr die Ausf√ºhrung\n",
        "def main():\n",
        "    print(\"üöÄ STARTE SPAN-BASIERTE PIIRANHA EVALUATION\")\n",
        "\n",
        "    # Evaluator initialisieren\n",
        "    evaluator = PIIRanhaSpanEvaluator()\n",
        "\n",
        "    # üìÇ Lade automatisch mehrere Beispieldateien aus dem Ordner \"data/\"\n",
        "    examples = load_multiple_examples(count=2)\n",
        "\n",
        "    # ‚úÖ Evaluiere alle Beispiele\n",
        "    multiple_results = evaluator.evaluate_multiple_examples(examples)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "7SZ8cZMlYWhi",
        "outputId": "7d05ab5a-d134-4424-fe8b-c8c6d4a9cd76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Hauptfunktion f√ºr die Ausf√ºhrung\\ndef main():\\n    print(\"üöÄ STARTE SPAN-BASIERTE PIIRANHA EVALUATION\")\\n\\n    # Evaluator initialisieren\\n    evaluator = PIIRanhaSpanEvaluator()\\n\\n    # üìÇ Lade automatisch mehrere Beispieldateien aus dem Ordner \"data/\"\\n    examples = load_multiple_examples(count=2)\\n\\n    # ‚úÖ Evaluiere alle Beispiele\\n    multiple_results = evaluator.evaluate_multiple_examples(examples)\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}